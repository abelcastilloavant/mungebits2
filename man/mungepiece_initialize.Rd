% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/mungepiece-initialize.R
\name{mungepiece_initialize}
\alias{mungepiece_initialize}
\title{Constructor for mungepiece class.}
\usage{
mungepiece_initialize(mungebit = NULL, train_args = list(),
  predict_args = train_args)
}
\arguments{
\item{mungebit}{mungebit. A mungebit \code{\link{mungebit}} representing
an abstract transformation of a data set, such as type conversion,
imputation, outlier detection, dimensionality reduction,
value replacement, and so on.}

\item{train_args}{list. Arguments to pass to the mungebit when it is
   run for the first time, i.e., on a \emph{training set} that will be
   fed to a predictive model and may be quite large. These arguments,
   passed directly to the mungebit's \code{train_function}, should
   contain domain-specific metadata that is relevant for applying the
   mungebit to this specific data set.

   For example, if the modeler knows certain columns do not contain
   missing values, they might pass a character vector of column names
   to an imputation mungebit that avoids attempting to impute the
   columns guaranteed to be fully present.}

\item{predict_args}{list. Arguments to pass to the mungebit when it
   is run for the second or subsequent time, i.e., on a \code{prediction set}
   that will usually be coming from a validation set or a real-time
   production environment. After the mungebit has been trained on the
   training set, it should be capable of predicting on
   \emph{single row data sets}, i.e., new "points" coming through in
   a live production setting.

   Usually, the prediction arguments will be the same as the training
   arguments for the mungepiece.}
}
\description{
A mungebit defines atomic data tranformation of an \emph{arbitrary}
data set. In order to fix the parameters that may be relevant for
a \emph{particular} data set (such as restricting its effect to
specific columns, fixing certain parameters such as imputation
method, or providing information that may contain domain knowledge)
we use a mungepiece.
}
\details{
A mungepiece is defined by the collection of

\enumerate{
  \item{A mungebit. }{The mungebit determines the qualitative nature
     of the data transformation. The mungebit may represent
     a discretization method, principal component analysis,
     replacement of outlier or special values, and so on.

If a training set represents automobile data and there are
     variables like "weight" or "make", these should not be
     hardcoded at all in the mungebit's \code{train} and \code{predict}
     functions. The mungebit should only represent that abstract
     \emph{mathematical} operation performed on the data set.}
  \item{Training arguments. }{While the mungebit represents the code
     necessary for performing some \emph{abstract mathematical operation}
     on the data set, the training arguments record the metadata
     used by the operation to perform the transformation on a particular
     data set.

For example, if we have an automobile data set and know the
     "weight" column has some missing values, we might pass a vector
     of column names that includes "weight" to the imputation mungebit.

If we have a medical dataset that includes special patient type
     codes and some of the codes were mistyped during data entry or
     are synonyms for the same underlying "type", we could pass a list
     of character vectors to a "grouper" mungebit that would condense
     the categorical feature by grouping like types.

If we know that some set of variables is predictive for modeling a
     particular statistical question but are unsure about the remaining
     variables, we could use this intuition to pass the list of known
     variables as exceptions to a "sure independence screening" mungebit.
     The mungebit would run a univariate regression against each variable
     not contained in the exceptions list and drop those totally uncorrelated
     with the dependent variable. This is a typical technique for high
     dimensionality reduction, and knowledge of the exceptions would reduce
     the computation time necessary for recording which variables are
     nonpredictive, an operation that may be very computationally expensive.

In short, the mungebit records \emph{what} we are doing to the dataset
     from an abstract level and does not contain any domain knowledge.
     The training arguments, the arguments passed to the mungebit's
     \code{train_function}, record the \emph{details} that pinpoint the
     abstract transformation to a particular training set intended for
     use with a predictive model.}
  \item{Prediction arguments. }{It is important to understand the
     train-predict dichotomy of the mungebit. If we are performing an
     imputation, the mungebit will record the means computed from the
     variables in the training set for the purpose of replacing \code{NA}
     values. The training arguments might be used for specifying to what
     columns the imputation should be restricted to.

The prediction arguments, by default the same as the training arguments,
     are metadata passed to the mungebit's \code{predict_function}, such as
     again the variables the imputation applies to. Sometimes the prediction
     arguments may differ slightly from the training arguments, such as when
     handling the dependent variable (which will not be present during
     prediction) or when the code used for prediction needs some further
     parametrization to replicate the behavior of the \code{train_function}
     on one-row data sets (i.e., real-time points in a production setting).}
}

In short, mungepieces \emph{parametrize} a \emph{single transformation}
of a data set \emph{for that particular data set}. While a mungebit is
abstract and domain-independent and may represent computations like
imputation, outlier detection, and dimensionality reduction, a mungepiece
records the human touch and domain knowledge that is necessary for
ensuring the mungebits operate on the appropriate features and optimize
space-time tradeoffs (for example, the modeler may know that certain
columns do not contain missing values and avoid passing them to the
imputation mungebit).
}
\examples{
\dontrun{
  doubler <- mungebit$new(column_transformation(function(x) x * 2))
  cols    <- c("Sepal.Length", "Petal.Length")
  mp      <- mungepiece$new(doubler, list(cols))
  iris2   <- mp$run(iris)
  stopifnot(identical(iris2[cols], 2 * iris[cols]))
}
}

